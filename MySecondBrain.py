__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

# ------------ åˆ†å‰²çº¿ ------------
# ä¸Šé¢è¿™ä¸‰è¡Œå¿…é¡»åœ¨æœ€å‰é¢ï¼
# ä¸‹é¢æ‰æ˜¯å…¶ä»–çš„ import

import streamlit as st
import os
import chromadb
# ... åé¢çš„ä»£ç import streamlit as st
import os
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import json
# å¼•å…¥ä¹‹å‰å†™å¥½çš„ ingest é€»è¾‘ (å‡è®¾ä½ æŠŠ universal_ingest.py é‡Œçš„å‡½æ•°å°è£…å¥½äº†)
# ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥ç®€åŒ–å†™åœ¨é‡Œé¢
import pysqlite3
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')


# 2. é¡µé¢è®¾ç½®
st.set_page_config(page_title="My Second Brain", layout="wide")
st.title("ğŸ§  æˆ‘çš„ç¬¬äºŒå¤§è„‘ (Agentç‰ˆ)")

# 3. åˆå§‹åŒ– (ç¼“å­˜èµ„æº)
@st.cache_resource
def init_system():
    # A. è¿ DeepSeek
    api_key = st.secrets["DEEPSEEK_API_KEY"]
    client = OpenAI(
        api_key=api_key, 
        base_url="https://api.deepseek.com"
    )
    # B. è¿æ•°æ®åº“
    chroma_client = chromadb.PersistentClient(path="./my_company_data")
    ef = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )
    collection = chroma_client.get_or_create_collection(name="second_brain", embedding_function=ef)
    return client, collection

client, collection = init_system()

# 5. ä¾§è¾¹æ ï¼šçŸ¥è¯†æŠ•å–‚ç«™ (ä¿®æ”¹ç‰ˆ)
with st.sidebar:
    st.header("ğŸ“‚ çŸ¥è¯†æŠ•å–‚")
    uploaded_file = st.file_uploader("ä¸Šä¼  TXT èµ„æ–™", type=["txt"])
    
    if uploaded_file and st.button("åƒæ‰å®ƒï¼"):
        # 1. è¯»å–å¹¶å­˜åº“
        text = uploaded_file.read().decode("utf-8")
        collection.add(
            documents=[text],
            ids=[uploaded_file.name]
        )
        st.success(f"å·²åå™¬: {uploaded_file.name}")
        
        # 2. ã€å…³é”®ä¿®æ”¹ã€‘å­˜å®Œä¹‹åï¼Œå¾€èŠå¤©è®°å½•é‡Œå¡ä¸€æ¡â€œç³»ç»Ÿé€šçŸ¥â€
        # è¿™æ · AI å°±çŸ¥é“ï¼šâ€œå“¦ï¼ŒåŸæ¥åˆšæ‰å­˜äº†ä¸ªæ–‡ä»¶ï¼Œé‚£ç”¨æˆ·é—®çš„æ—¶å€™æˆ‘è¦å»æŸ¥åº“ã€‚â€
        st.session_state.messages.append({
            "role": "assistant", 
            "content": f"âœ… æˆ‘å·²ç»å­¦ä¹ äº†æ–‡ä»¶ **{uploaded_file.name}** çš„å†…å®¹ã€‚ç°åœ¨ä½ å¯ä»¥é—®æˆ‘å…³äºå®ƒçš„é—®é¢˜äº†ï¼"
        })
        
        # å¼ºåˆ¶åˆ·æ–°é¡µé¢ï¼Œè®©è¿™å¥è¯ç«‹åˆ»æ˜¾ç¤ºå‡ºæ¥
        st.rerun()

# 5. å®šä¹‰ Agent å·¥å…·å‡½æ•°
def search_knowledge(query):
    results = collection.query(query_texts=[query], n_results=1)
    if not results['documents'][0]:
        return "æ•°æ®åº“é‡Œæ²¡æœ‰ç›¸å…³ä¿¡æ¯ã€‚"
    return results['documents'][0][0]

def save_file(filename, content):
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    return f"æ–‡ä»¶å·²ä¿å­˜: {filename}"

# å·¥å…· Schema
tools = [
    {
        "type": "function",
        "function": {
            "name": "search_knowledge",
            "description": "æŸ¥æ•°æ®åº“",
            "parameters": {"type": "object", "properties": {"query": {"type": "string"}}, "required": ["query"]}
        }
    },
    {
        "type": "function",
        "function": {
            "name": "save_file",
            "description": "ä¿å­˜æ–‡ä»¶",
            "parameters": {"type": "object", "properties": {"filename": {"type": "string"}, "content": {"type": "string"}}, "required": ["filename", "content"]}
        }
    }
]

# 6. èŠå¤©ä¸»é€»è¾‘
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²
for msg in st.session_state.messages:
    if msg["role"] != "tool": # ä¸æ˜¾ç¤ºå·¥å…·è°ƒç”¨çš„ä¸­é—´æ‚éŸ³
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# å¤„ç†è¾“å…¥
if prompt := st.chat_input("é—®æˆ‘ä»»ä½•äº‹ï¼Œæˆ–è€…è®©æˆ‘å¸®ä½ æ€»ç»“ä¿å­˜..."):
    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # æ„é€ è¯·æ±‚ (å¸¦ä¸Šå†å²è®°å½•ï¼Œé˜²æ­¢å¤±å¿†)
    # æ³¨æ„ï¼šçœŸå®é¡¹ç›®ä¸­è¦å¤„ç† messages æ ¼å¼ï¼Œè¿™é‡Œç®€åŒ–åªå‘æœ€è¿‘å‡ æ¡
    api_messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æŒ‰éœ€ä½¿ç”¨å·¥å…·ã€‚"}
    ] + [m for m in st.session_state.messages if m["role"] != "tool"] # ç®€åŒ–å¤„ç†

    # ç¬¬ä¸€è½®è°ƒç”¨
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=api_messages,
        tools=tools
    )
    msg = response.choices[0].message
    
    # å¦‚æœ AI è¦è°ƒå·¥å…·
    if msg.tool_calls:
        # æ˜¾ç¤º AI æ­£åœ¨æ€è€ƒçš„åŠ¨æ•ˆ
        with st.chat_message("assistant"):
            st.markdown("âš™ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·å¤„ç†...")
            
        for tool_call in msg.tool_calls:
            fname = tool_call.function.name
            args = json.loads(tool_call.function.arguments)
            
            tool_result = ""
            if fname == "search_knowledge":
                tool_result = search_knowledge(args["query"])
            elif fname == "save_file":
                tool_result = save_file(args["filename"], args["content"])
            
            # æŠŠå·¥å…·ç»“æœå¡å›ç»™ AI (è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä¸å­˜å…¥ session_state æ˜¾ç¤ºç»™ç”¨æˆ·çœ‹)
            api_messages.append(msg)
            api_messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": str(tool_result)
            })
            
        # ç¬¬äºŒè½®è°ƒç”¨ï¼šç”Ÿæˆæœ€ç»ˆå›ç­”
        final_resp = client.chat.completions.create(
            model="deepseek-chat",
            messages=api_messages
        )
        ai_reply = final_resp.choices[0].message.content
        
        st.chat_message("assistant").markdown(ai_reply)
        st.session_state.messages.append({"role": "assistant", "content": ai_reply})
        
    else:
        # ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥å›
        st.chat_message("assistant").markdown(msg.content)
        st.session_state.messages.append({"role": "assistant", "content": msg.content})
